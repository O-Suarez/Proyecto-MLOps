{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70224804-26da-4f51-981f-223665c7165d",
   "metadata": {},
   "source": [
    "## Generar Datos Sintéticos Usando Interpolación y Transformaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2366ab-4cc4-44db-88f8-7c25b5f431eb",
   "metadata": {},
   "source": [
    "#### Cargando Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67757039-e4e4-4c8f-af76-d3aff22fcd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Path\n",
    "path = './data/'\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(path+'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283b6574-acd4-4b53-8bd7-ff5689726064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4746 entries, 0 to 4745\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   gender         4746 non-null   int64  \n",
      " 1   C_api          4746 non-null   object \n",
      " 2   C_man          4746 non-null   int64  \n",
      " 3   E_NEds         4746 non-null   int64  \n",
      " 4   E_Bpag         4746 non-null   int64  \n",
      " 5   firstDay       4746 non-null   int64  \n",
      " 6   lastDay        4746 non-null   int64  \n",
      " 7   NEds           4746 non-null   int64  \n",
      " 8   NDays          4746 non-null   int64  \n",
      " 9   NActDays       4746 non-null   int64  \n",
      " 10  NPages         4746 non-null   int64  \n",
      " 11  NPcreated      4746 non-null   int64  \n",
      " 12  pagesWomen     4746 non-null   int64  \n",
      " 13  wikiprojWomen  4746 non-null   int64  \n",
      " 14  ns_user        4746 non-null   int64  \n",
      " 15  ns_wikipedia   4746 non-null   int64  \n",
      " 16  ns_talk        4746 non-null   int64  \n",
      " 17  ns_userTalk    4746 non-null   int64  \n",
      " 18  ns_content     4746 non-null   int64  \n",
      " 19  weightIJ       4746 non-null   float64\n",
      " 20  NIJ            4746 non-null   int64  \n",
      "dtypes: float64(1), int64(19), object(1)\n",
      "memory usage: 778.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19beb2d6-af42-4e7e-816c-92d48d0d2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Cargar tu DataFrame original\n",
    "original_data = df\n",
    "\n",
    "#lista para almacenar las filas sintéticas\n",
    "synthetic_rows = []\n",
    "\n",
    "# Generar datos sintéticos\n",
    "for index, row in original_data.iterrows():\n",
    "    # Crear una copia de la fila\n",
    "    new_row = row.copy()\n",
    "    \n",
    "    # Generar datos sintéticos basados en la lógica de cada columna\n",
    "    new_row['gender'] = np.random.choice([0, 1, 2], p=[0.2, 0.4, 0.4])  # Proporción arbitraria para gender\n",
    "    new_row['C_api'] = np.random.choice(['male', 'female', 'unknown'], p=[0.4, 0.4, 0.2])\n",
    "    new_row['C_man'] = np.random.choice([1, 2, 3], p=[0.4, 0.4, 0.2])\n",
    "    \n",
    "    new_row['E_NEds'] = np.random.randint(0, 4)  # Estrato entre 0 y 3\n",
    "    new_row['E_Bpag'] = np.random.randint(0, 4)  # Estrato entre 0 y 3\n",
    "\n",
    "    # Generar fechas en formato YYYYMMDDHHMMSS\n",
    "    first_day_timestamp = np.random.randint(20000000000000, 20230000000000)  # 2000-01-01 00:00:00 hasta 2023-12-31 23:59:59\n",
    "    last_day_timestamp = first_day_timestamp + np.random.randint(0, 1000000)  # Se asume que la fecha final es posterior a la inicial\n",
    "    new_row['firstDay'] = first_day_timestamp\n",
    "    new_row['lastDay'] = last_day_timestamp\n",
    "\n",
    "    # Calcular los valores restantes\n",
    "    new_row['NEds'] = np.random.randint(1, 100)  # Total de ediciones (al menos 1)\n",
    "    new_row['NDays'] = (last_day_timestamp - first_day_timestamp) // 1000000 + 1  # Días totales (HHMMSS)\n",
    "    new_row['NActDays'] = np.random.randint(1, new_row['NDays'] + 1)  # Días activos, al menos 1 y no más que NDays\n",
    "    new_row['NPages'] = np.random.randint(1, 50)  # Número de páginas editadas\n",
    "    new_row['NPcreated'] = np.random.randint(0, 20)  # Páginas creadas\n",
    "    \n",
    "    # Asegurarse de que NEds sea mayor que 0 antes de usarlo\n",
    "    if new_row['NEds'] > 0:\n",
    "        new_row['pagesWomen'] = np.random.randint(0, new_row['NEds'])  # Ediciones en páginas relacionadas con mujeres\n",
    "        new_row['wikiprojWomen'] = np.random.randint(0, new_row['NEds'])  # Ediciones en WikiProjects relacionados con mujeres\n",
    "        new_row['ns_user'] = np.random.randint(0, new_row['NEds'])  # Ediciones en el namespace de usuario\n",
    "        new_row['ns_wikipedia'] = np.random.randint(0, new_row['NEds'])  # Ediciones en el namespace de Wikipedia\n",
    "        new_row['ns_talk'] = np.random.randint(0, new_row['NEds'])  # Ediciones en el namespace de talk\n",
    "        new_row['ns_userTalk'] = np.random.randint(0, new_row['NEds'])  # Ediciones en el namespace de user talk\n",
    "        new_row['ns_content'] = np.random.randint(0, new_row['NEds'])  # Ediciones en páginas de contenido\n",
    "    else:\n",
    "        # Asignar 0 si NEds es 0\n",
    "        new_row['pagesWomen'] = 0\n",
    "        new_row['wikiprojWomen'] = 0\n",
    "        new_row['ns_user'] = 0\n",
    "        new_row['ns_wikipedia'] = 0\n",
    "        new_row['ns_talk'] = 0\n",
    "        new_row['ns_userTalk'] = 0\n",
    "        new_row['ns_content'] = 0\n",
    "\n",
    "    new_row['weightIJ'] = np.random.uniform(0.5, 1.5)  # Peso de corrección para el estrato IJ\n",
    "    new_row['NIJ'] = np.random.randint(1, 100)  # Número de elementos en el estrato IJ\n",
    "\n",
    "    # Agregar la nueva fila a la lista\n",
    "    synthetic_rows.append(new_row)\n",
    "\n",
    "# Crear un DataFrame a partir de la lista de filas\n",
    "synthetic_data = pd.DataFrame(synthetic_rows, columns=original_data.columns)\n",
    "\n",
    "for column in original_data.select_dtypes(include=[np.int64]).columns:\n",
    "    synthetic_data[column] = synthetic_data[column].astype(np.int64)\n",
    "\n",
    "for column in original_data.select_dtypes(include=[np.float64]).columns:\n",
    "    synthetic_data[column] = synthetic_data[column].astype(np.float64)\n",
    "\n",
    "# Para asegurar que las columnas de fechas mantengan su tipo de dato\n",
    "\n",
    "date_columns = ['firstDay', 'lastDay']  # Lista las columnas que representan días\n",
    "for column in date_columns:\n",
    "    synthetic_data[column] = synthetic_data[column].astype(np.int64)  # Asegúrate de que sean enteros\n",
    "\n",
    "\n",
    "# Obtener la hora actual\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Guardar el nuevo dataset sintético en un archivo CSV\n",
    "synthetic_data.to_csv(path+'synthetic_interpolated_dataset'+current_time+'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88b5c5f-1bbc-4fe4-8716-a2e8bc4e7969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4746 entries, 0 to 4745\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   gender         4746 non-null   int64  \n",
      " 1   C_api          4746 non-null   object \n",
      " 2   C_man          4746 non-null   int64  \n",
      " 3   E_NEds         4746 non-null   int64  \n",
      " 4   E_Bpag         4746 non-null   int64  \n",
      " 5   firstDay       4746 non-null   int64  \n",
      " 6   lastDay        4746 non-null   int64  \n",
      " 7   NEds           4746 non-null   int64  \n",
      " 8   NDays          4746 non-null   int64  \n",
      " 9   NActDays       4746 non-null   int64  \n",
      " 10  NPages         4746 non-null   int64  \n",
      " 11  NPcreated      4746 non-null   int64  \n",
      " 12  pagesWomen     4746 non-null   int64  \n",
      " 13  wikiprojWomen  4746 non-null   int64  \n",
      " 14  ns_user        4746 non-null   int64  \n",
      " 15  ns_wikipedia   4746 non-null   int64  \n",
      " 16  ns_talk        4746 non-null   int64  \n",
      " 17  ns_userTalk    4746 non-null   int64  \n",
      " 18  ns_content     4746 non-null   int64  \n",
      " 19  weightIJ       4746 non-null   float64\n",
      " 20  NIJ            4746 non-null   int64  \n",
      "dtypes: float64(1), int64(19), object(1)\n",
      "memory usage: 815.7+ KB\n"
     ]
    }
   ],
   "source": [
    "synthetic_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7982a41-8dc2-420a-9daf-6c91f97424fc",
   "metadata": {},
   "source": [
    "## Generar Datos Sintéticos Usando Interpolación y Transformaciones\n",
    "\n",
    "La generación de datos sintéticos mediante interpolación y transformaciones es una técnica utilizada para crear conjuntos de datos artificiales que imitan las características estadísticas de un conjunto de datos real. Este método es útil para mantener la privacidad de los datos sensibles y para entrenar modelos de machine learning sin la necesidad de usar datos reales.\n",
    "\n",
    "### Proceso General:\n",
    "\n",
    "1. **Selección de un Conjunto de Datos Base**: Se comienza con un conjunto de datos real que contiene las variables de interés.\n",
    "\n",
    "2. **Análisis Estadístico**: Se realiza un análisis para entender la distribución y la correlación entre las variables. Esto puede incluir el cálculo de medias, varianzas, y otros estadísticos descriptivos.\n",
    "\n",
    "3. **Interpolación**: Se utilizan técnicas de interpolación para estimar nuevos valores basados en los existentes. Esto permite generar datos adicionales que se ajusten a las distribuciones observadas.\n",
    "\n",
    "4. **Transformaciones**: Se pueden aplicar transformaciones a los datos, como escalado o normalización, para garantizar que los datos sintéticos mantengan las propiedades del conjunto original.\n",
    "\n",
    "5. **Validación**: Finalmente, se valida el conjunto de datos sintéticos para asegurarse de que su estructura y propiedades sean coherentes con el conjunto de datos original.\n",
    "\n",
    "Este enfoque es particularmente útil en escenarios donde se necesita crear datos para pruebas o para simular situaciones en entornos controlados.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d3b2a1-8d0b-4dff-93ed-056caae1c5df",
   "metadata": {},
   "source": [
    "## Generar Datos Sintéticos Usando  Faker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155229e7-3293-4b18-9f3f-e93dcf169563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from datetime import datetime\n",
    "\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Número de filas que deseas generar\n",
    "num_rows = 1000  # Ajusta este valor según lo necesites\n",
    "\n",
    "# Crear una lista para almacenar las filas sintéticas\n",
    "synthetic_rows = []\n",
    "\n",
    "# Generar datos sintéticos\n",
    "for _ in range(num_rows):\n",
    "    # Generar firstDay y lastDay asegurando que firstDay es antes que lastDay\n",
    "    first_day = fake.date_time_this_decade(before_now=True)\n",
    "    last_day = fake.date_time_this_decade(after_now=True)\n",
    "\n",
    "    # Asegurarse de que last_day sea después de first_day\n",
    "    if last_day < first_day:\n",
    "        first_day, last_day = last_day, first_day\n",
    "\n",
    "    new_row = {\n",
    "        'gender': np.random.choice([0, 1, 2], p=[0.2, 0.4, 0.4]),  # Proporción de género\n",
    "        'C_api': fake.random_element(elements=['male', 'female', 'unknown']),\n",
    "        'C_man': np.random.choice([1, 2, 3], p=[0.4, 0.4, 0.2]),\n",
    "        'E_NEds': np.random.randint(0, 4),  # Estrato entre 0 y 3\n",
    "        'E_Bpag': np.random.randint(0, 4),  # Estrato entre 0 y 3\n",
    "        'firstDay': first_day.strftime(\"%Y%m%d%H%M%S\"),\n",
    "        'lastDay': last_day.strftime(\"%Y%m%d%H%M%S\"),\n",
    "        'NEds': np.random.randint(1, 100),  # Total de ediciones (al menos 1)\n",
    "        'NPages': np.random.randint(1, 50),  # Número de páginas editadas\n",
    "        'NPcreated': np.random.randint(0, 20),  # Páginas creadas\n",
    "        'weightIJ': np.random.uniform(0.5, 1.5),  # Peso de corrección para el estrato IJ\n",
    "        'NIJ': np.random.randint(1, 100),  # Número de elementos en el estrato IJ\n",
    "    }\n",
    "    \n",
    "    # Calcular los valores derivados\n",
    "    new_row['NDays'] = (int(new_row['lastDay']) - int(new_row['firstDay'])) // 1000000 + 1  # Días totales\n",
    "\n",
    "    # Verificar que NDays sea mayor que 0\n",
    "    if new_row['NDays'] > 0:\n",
    "        new_row['NActDays'] = np.random.randint(1, new_row['NDays'] + 1)  # Días activos\n",
    "    else:\n",
    "        new_row['NActDays'] = 0  # Asignar 0 si NDays es 0\n",
    "\n",
    "    # Asegurarse de que NEds sea mayor que 0 antes de usarlo para generar otros campos\n",
    "    if new_row['NEds'] > 0:\n",
    "        new_row['pagesWomen'] = np.random.randint(0, new_row['NEds'] + 1)  # Ediciones en páginas relacionadas con mujeres\n",
    "        new_row['wikiprojWomen'] = np.random.randint(0, new_row['NEds'] + 1)  # Ediciones en WikiProjects relacionados con mujeres\n",
    "        new_row['ns_user'] = np.random.randint(0, new_row['NEds'] + 1)  # Ediciones en el namespace de usuario\n",
    "        new_row['ns_wikipedia'] = np.random.randint(0, new_row['NEds'] + 1)  # Ediciones en el namespace de Wikipedia\n",
    "        new_row['ns_talk'] = np.random.randint(0, new_row['NEds'] + 1)  # Ediciones en el namespace de talk\n",
    "        new_row['ns_userTalk'] = np.random.randint(0, new_row['NEds'] + 1)  # Ediciones en el namespace de user talk\n",
    "        new_row['ns_content'] = np.random.randint(0, new_row['NEds'] + 1)  # Ediciones en páginas de contenido\n",
    "    else:\n",
    "        # Asignar 0 si NEds es 0\n",
    "        new_row['pagesWomen'] = 0\n",
    "        new_row['wikiprojWomen'] = 0\n",
    "        new_row['ns_user'] = 0\n",
    "        new_row['ns_wikipedia'] = 0\n",
    "        new_row['ns_talk'] = 0\n",
    "        new_row['ns_userTalk'] = 0\n",
    "        new_row['ns_content'] = 0\n",
    "\n",
    "    # Agregar la nueva fila a la lista\n",
    "    synthetic_rows.append(new_row)\n",
    "\n",
    "# Crear un DataFrame a partir de la lista de filas\n",
    "synthetic_data = pd.DataFrame(synthetic_rows)\n",
    "\n",
    "# Asegurarse de que las columnas numéricas mantengan su tipo original\n",
    "for column in synthetic_data.select_dtypes(include=[np.int64]).columns:\n",
    "    synthetic_data[column] = synthetic_data[column].astype(np.int64)\n",
    "\n",
    "for column in synthetic_data.select_dtypes(include=[np.float64]).columns:\n",
    "    synthetic_data[column] = synthetic_data[column].astype(np.float64)\n",
    "\n",
    "# Generar un nombre de archivo único usando la fecha y hora actual\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Guardar el nuevo dataset sintético en un archivo CSV\n",
    "synthetic_data.to_csv(path + f'synthetic_faker_dataset_{current_time}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a511cee4-4173-4cb3-8331-4d878652efea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   gender         1000 non-null   int64  \n",
      " 1   C_api          1000 non-null   object \n",
      " 2   C_man          1000 non-null   int64  \n",
      " 3   E_NEds         1000 non-null   int64  \n",
      " 4   E_Bpag         1000 non-null   int64  \n",
      " 5   firstDay       1000 non-null   object \n",
      " 6   lastDay        1000 non-null   object \n",
      " 7   NEds           1000 non-null   int64  \n",
      " 8   NPages         1000 non-null   int64  \n",
      " 9   NPcreated      1000 non-null   int64  \n",
      " 10  weightIJ       1000 non-null   float64\n",
      " 11  NIJ            1000 non-null   int64  \n",
      " 12  NDays          1000 non-null   int64  \n",
      " 13  NActDays       1000 non-null   int64  \n",
      " 14  pagesWomen     1000 non-null   int64  \n",
      " 15  wikiprojWomen  1000 non-null   int64  \n",
      " 16  ns_user        1000 non-null   int64  \n",
      " 17  ns_wikipedia   1000 non-null   int64  \n",
      " 18  ns_talk        1000 non-null   int64  \n",
      " 19  ns_userTalk    1000 non-null   int64  \n",
      " 20  ns_content     1000 non-null   int64  \n",
      "dtypes: float64(1), int64(17), object(3)\n",
      "memory usage: 164.2+ KB\n"
     ]
    }
   ],
   "source": [
    "synthetic_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a9c73c-69fa-44ea-8a7d-ae421ef4bb6d",
   "metadata": {},
   "source": [
    "## Generar Datos Sintéticos Usando Faker\n",
    "\n",
    "Faker es una biblioteca de Python que permite generar datos ficticios de manera rápida y eficiente. Esta herramienta es ideal para pruebas, desarrollo y cualquier situación en la que se necesite un conjunto de datos sintéticos realista.\n",
    "\n",
    "### Descripción\n",
    "- **Generar Datos Sintéticos Usando Interpolación y Transformaciones**: Este apartado describe el enfoque de usar datos reales como base para crear un conjunto sintético mediante técnicas de interpolación y transformaciones.\n",
    "  \n",
    "- **Generar Datos Sintéticos Usando Faker**: Aquí se explica cómo usar la biblioteca Faker para generar datos sintéticos de manera eficiente y práctica.\n",
    "\n",
    "Puedes personalizar y ampliar cada sección según sea necesario para adaptarse a tu audiencia y contexto. ¡Avísame si necesitas más detalles o ajustes!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1586764-1847-41ac-9385-62d144d8a1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
